{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d450f6-d874-4883-ad86-df7f87dc0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 20:06:56,635\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8268 \u001b[39m\u001b[22m\n",
      "2022-09-29 20:07:03,400\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8268 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import deep_nmmo\n",
    "from deep_nmmo.envs.team_based_env.teams.custom_team import CustomTeam\n",
    "from deep_nmmo.utils import get_class_from_path, get_module_from_path\n",
    "from deep_nmmo.envs.team_based_env.env_configs.custom_competition_config import CustomCompetitionConfig\n",
    "from deep_nmmo.envs.team_based_env.loops.utils import init_env_params, reset_teams, reset_env\n",
    "\n",
    "import nmmo\n",
    "from nmmo import config\n",
    "from nmmo.io import action\n",
    "from nmmo import scripting, material, Serialized\n",
    "from nmmo.systems import skill, item\n",
    "from nmmo.lib import colors\n",
    "from nmmo import action as Action\n",
    "\n",
    "\n",
    "import neurips2022nmmo\n",
    "from neurips2022nmmo.scripted import baselines\n",
    "from neurips2022nmmo import Team\n",
    "from neurips2022nmmo import CompetitionConfig, scripted, RollOut, TeamBasedEnv\n",
    "from neurips2022nmmo.scripted import attack, move\n",
    "\n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "# from ray.rllib.env.multi_agent_env import make_multi_agent\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "\n",
    "from ray.rllib.models.modelv2 import restore_original_dimensions\n",
    "from collections.abc import Mapping\n",
    "\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.typing import (\n",
    "    # AgentID,\n",
    "    # EnvCreator,\n",
    "    # EnvID,\n",
    "    # EnvType,\n",
    "    MultiAgentDict,\n",
    "    # MultiEnvDict,\n",
    ")\n",
    "\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from typing import Dict, Any, Type, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b06c5-7760-4a2d-9ac6-8c6e1b09e7c6",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Create RLLibScriptedBaseline class to wrap around neurips2022nmmo.scripted.baselines agents so that agents are compatible with RLlib environments. Should inherit from RLlib Policy base class\n",
    "     - May need to have wrapper class for Team as well. Need to ensure all this still works when making submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0239057-a14d-43f5-a8e6-0963e0614278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zciccwf/personal/projects/neurips2022-nmmo-starter-kit/deep_nmmo/deep_nmmo/envs/rllib_multi_agent_team_based_env/utils.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import defaultdict, Mapping\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from deep_nmmo.envs.rllib_multi_agent_team_based_env.env import RLlibMultiAgentTeamBasedEnv\n",
    "from deep_nmmo.envs.rllib_multi_agent_team_based_env.agents.rllib_random_policy import RLlibRandomPolicy\n",
    "\n",
    "    \n",
    "    \n",
    "# env config\n",
    "path_to_env_cls = 'neurips2022nmmo.TeamBasedEnv'\n",
    "path_to_env_config_cls = 'deep_nmmo.envs.team_based_env.env_configs.custom_competition_config.CustomCompetitionConfig'\n",
    "env_config_kwargs = None\n",
    "# teams_config = {\n",
    "#     'Combat':\n",
    "#         {\n",
    "#             'path_to_team_cls': 'neurips2022nmmo.scripted.CombatTeam'\n",
    "#         },\n",
    "#     'Mixture':\n",
    "#         {\n",
    "#             'path_to_team_cls': 'neurips2022nmmo.scripted.MixtureTeam'\n",
    "#         },\n",
    "# }\n",
    "# rllib_paths_to_scripted_agents_cls = {\n",
    "#                                     '0': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     '1': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     '2': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     '3': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     '4': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     '5': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     '6': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "#                                     }\n",
    "\n",
    "num_players_per_team = 8\n",
    "# will overwrite agents kwargs with observation and action space and player index when initialising teams in RLlib env\n",
    "custom_team_kwargs = {'agents_cls': [RLlibRandomPolicy for _ in range(num_players_per_team)], \n",
    "                      'agents_kwargs': [None for _ in range(num_players_per_team)],\n",
    "                     }\n",
    "\n",
    "teams_config = {\n",
    "    # 'RLlib': {'cls': RLlibScriptedHybridAgentTeam, 'kwargs': {'paths_to_scripted_agents_cls': rllib_paths_to_scripted_agents_cls}},\n",
    "    \n",
    "    # 'Combat-1': {'cls': neurips2022nmmo.scripted.CombatTeam, 'kwargs': {'team_id': 1}},\n",
    "    # 'Combat-2': {'cls': neurips2022nmmo.scripted.CombatTeam, 'kwargs': {'team_id': 2}},\n",
    "    # 'Mixture-1': {'cls': neurips2022nmmo.scripted.MixtureTeam, 'kwargs': {'team_id': 3}},\n",
    "    \n",
    "    'R-1': {'cls': deep_nmmo.envs.team_based_env.teams.custom_team.CustomTeam, 'kwargs': custom_team_kwargs},\n",
    "    'R-2': {'cls': deep_nmmo.envs.team_based_env.teams.custom_team.CustomTeam, 'kwargs': custom_team_kwargs},\n",
    "    'R-3': {'cls': deep_nmmo.envs.team_based_env.teams.custom_team.CustomTeam, 'kwargs': custom_team_kwargs},\n",
    "    \n",
    "    \n",
    "}\n",
    "# teams_copies = [1, 2]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092851a0-2b0a-46df-8ac4-64ff99a3e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▎                                                                                                                                                              | 2/40 [00:00<00:03, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 40 maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 39/40 [00:02<00:00, 13.05it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "env_config = get_class_from_path(path_to_env_config_cls)()\n",
    "ma_env = RLlibMultiAgentTeamBasedEnv(env_config=env_config,\n",
    "                                     # path_to_env_cls=path_to_env_cls,\n",
    "                                     # path_to_env_config_cls=path_to_env_config_cls,\n",
    "                                     teams_config=teams_config)\n",
    "observations = ma_env.reset()\n",
    "teams, agent_id_to_agent = ma_env.teams, ma_env.agent_id_to_agent\n",
    "print(f'')\n",
    "# print(f'RESET\\nobs:\\n{obs}\\nteams:\\n{teams}')\n",
    "print(f'Reset teams and obs')\n",
    "step_counter = 1\n",
    "while observations:\n",
    "    print(f'\\nStep {step_counter}')\n",
    "    print(f'Step observation keys: {observations.keys()}')\n",
    "    # agent_to_actions = {agent_id: agent(observations[agent_id]) for agent_id, agent in agent_id_to_agent.items()}\n",
    "    \n",
    "    agent_to_actions = {}\n",
    "    for agent_id in observations.keys():\n",
    "        # print(f'\\nagent_id: {agent_id}')\n",
    "        # print(f'agent: {agent}')\n",
    "        agent = agent_id_to_agent[agent_id]\n",
    "        # actions = agent(observations[agent_id])\n",
    "        # actions = agent.compute_single_action(observations[agent_id])\n",
    "        actions, state_outs, info = agent.compute_actions(observations[agent_id])\n",
    "        print(f'agent ob: {agent.ob}')\n",
    "        # print(f'actions: {actions}')\n",
    "        agent_to_actions[agent_id] = actions\n",
    "    \n",
    "    observations, rewards, dones, infos = ma_env.step(agent_to_actions)\n",
    "    print(f'Completed step')\n",
    "    break # DEBUG\n",
    "    step_counter += 1\n",
    "    \n",
    "print(f'\\nEPISODE COMPLETED!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d812990-43db-4052-b944-de070346b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from deep_nmmo.envs.rllib_multi_agent_team_based_env.env import RLlibMultiAgentTeamBasedEnv\n",
    "from deep_nmmo.envs.rllib_multi_agent_team_based_env.agents.rllib_random_policy import RLlibRandomPolicy\n",
    "\n",
    "\n",
    "path_to_rllib_trainer_cls = 'ray.rllib.agents.ppo.PPOTrainer'\n",
    "\n",
    "path_to_env_config_cls = 'deep_nmmo.envs.team_based_env.env_configs.custom_competition_config.CustomCompetitionConfig'\n",
    "\n",
    "num_players_per_team = 8\n",
    "# will overwrite agents kwargs with observation and action space and player index when initialising teams in RLlib env\n",
    "custom_team_kwargs = {'agents_cls': [RLlibRandomPolicy for _ in range(num_players_per_team)], \n",
    "                      'agents_kwargs': [None for _ in range(num_players_per_team)],\n",
    "                     }\n",
    "\n",
    "teams_config = {\n",
    "    # 'RLlib': {'cls': RLlibScriptedHybridAgentTeam, 'kwargs': {'paths_to_scripted_agents_cls': rllib_paths_to_scripted_agents_cls}},\n",
    "    \n",
    "    # 'Combat-1': {'cls': neurips2022nmmo.scripted.CombatTeam, 'kwargs': {'team_id': 1}},\n",
    "    # 'Combat-2': {'cls': neurips2022nmmo.scripted.CombatTeam, 'kwargs': {'team_id': 2}},\n",
    "    # 'Mixture-1': {'cls': neurips2022nmmo.scripted.MixtureTeam, 'kwargs': {'team_id': 3}},\n",
    "    \n",
    "    'R-1': {'cls': deep_nmmo.envs.team_based_env.teams.custom_team.CustomTeam, 'kwargs': custom_team_kwargs},\n",
    "    'R-2': {'cls': deep_nmmo.envs.team_based_env.teams.custom_team.CustomTeam, 'kwargs': custom_team_kwargs},\n",
    "    'R-3': {'cls': deep_nmmo.envs.team_based_env.teams.custom_team.CustomTeam, 'kwargs': custom_team_kwargs},\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "env_config = get_class_from_path(path_to_env_config_cls)()\n",
    "\n",
    "policies = {}\n",
    "policy_id = 1\n",
    "num_teams, num_players_per_team = 3, 8\n",
    "for _ in range(num_teams):\n",
    "    player_idx = 0\n",
    "    for _ in range(num_players_per_team):\n",
    "        policies[str(policy_id)] = PolicySpec(\n",
    "                                    policy_class=RLlibRandomPolicy, # infer from env\n",
    "                                    # observation_space=dummy_env.observation_space(player_id),\n",
    "                                    # action_space=dummy_env.action_space(player_id),\n",
    "                                    config={'env_config': env_config, 'idx': player_idx},\n",
    "                                )\n",
    "        policy_id += 1\n",
    "        player_idx += 1\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    '''Maps agent ID (int) to corresponding policy ID (str) of policy which agent should use.'''\n",
    "    print(f'>>> Mapping agent_id {agent_id} to {str(agent_id)}')\n",
    "    return str(agent_id)\n",
    "\n",
    "multiagent_config = {\n",
    "    'policies': policies,\n",
    "    'policy_mapping_fn': policy_mapping_fn,\n",
    "    'policies_to_train': [],\n",
    "}\n",
    "\n",
    "env_config = {\n",
    "    # 'path_to_env_cls': path_to_env_cls,\n",
    "    # 'path_to_env_config_cls': path_to_env_config_cls,\n",
    "    'env_config': env_config,\n",
    "    'teams_config': teams_config,\n",
    "}\n",
    "\n",
    "\n",
    "rllib_config = {\n",
    "    'env': 'ma_env',\n",
    "    \n",
    "    'env_config': env_config,\n",
    "    \n",
    "    'disable_env_checking': True,\n",
    "    # 'disable_env_checking': False,\n",
    "    \n",
    "    'framework': 'torch',\n",
    "    \n",
    "    'multiagent': multiagent_config,\n",
    "    \n",
    "    'num_workers': 0,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4040a863-2670-41b5-b0ce-f84c2e8133f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "# register env with ray\n",
    "register_env('ma_env', lambda env_config: RLlibMultiAgentTeamBasedEnv(**env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d5548c-6291-4692-9caa-b1363a962487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 20:32:21,075\tWARNING multi_agent.py:121 -- `config.multiagent.policies_to_train` is empty! Make sure - if you would like to learn at least one policy - to add its ID to that list.\n",
      "  5%|████████▎                                                                                                                                                              | 2/40 [00:00<00:02, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 40 maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 13.37it/s]\n",
      "  5%|████████▎                                                                                                                                                              | 2/40 [00:00<00:02, 14.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 40 maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 14.14it/s]\n",
      "2022-09-29 20:32:28,765\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised trainer\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# merge rllibg trainer's default config with specified config\n",
    "path_to_agent = '.'.join(path_to_rllib_trainer_cls.split('.')[:-1])\n",
    "_rllib_config = get_module_from_path(path_to_agent).DEFAULT_CONFIG.copy()\n",
    "_rllib_config.update(rllib_config)\n",
    "# print(_rllib_config)\n",
    "\n",
    "# init rllib trainer\n",
    "trainer = get_class_from_path(path_to_rllib_trainer_cls)(config=_rllib_config)\n",
    "print(f'Initialised trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fbf91e4-027b-403d-b2bf-b267f0611fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~ RESET ~~~\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 24 dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n",
      ">>> Mapping agent_id 1 to 1\n",
      ">>> Mapping agent_id 2 to 2\n",
      ">>> Mapping agent_id 3 to 3\n",
      ">>> Mapping agent_id 4 to 4\n",
      ">>> Mapping agent_id 5 to 5\n",
      ">>> Mapping agent_id 6 to 6\n",
      ">>> Mapping agent_id 7 to 7\n",
      ">>> Mapping agent_id 8 to 8\n",
      ">>> Mapping agent_id 9 to 9\n",
      ">>> Mapping agent_id 10 to 10\n",
      ">>> Mapping agent_id 11 to 11\n",
      ">>> Mapping agent_id 12 to 12\n",
      ">>> Mapping agent_id 13 to 13\n",
      ">>> Mapping agent_id 14 to 14\n",
      ">>> Mapping agent_id 15 to 15\n",
      ">>> Mapping agent_id 16 to 16\n",
      ">>> Mapping agent_id 17 to 17\n",
      ">>> Mapping agent_id 18 to 18\n",
      ">>> Mapping agent_id 19 to 19\n",
      ">>> Mapping agent_id 20 to 20\n",
      ">>> Mapping agent_id 21 to 21\n",
      ">>> Mapping agent_id 22 to 22\n",
      ">>> Mapping agent_id 23 to 23\n",
      ">>> Mapping agent_id 24 to 24\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   1.   0. ...  40. 277.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4221be0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   2.   0. ...  40. 279.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf9bbc70>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  40. 281.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d760>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   4.   0. ...  40. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d820>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   5.   0. ...  40. 285.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d610>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   6.   0. ...  40. 287.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4701ca0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  40. 289.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4221c40>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   8.   0. ...  40. 291.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4221b20>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   9.   0. ... 159. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c42bec40>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d5e0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 163. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524dac0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  12.   0. ... 165. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524db80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  13.   0. ... 167. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524dc40>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d6a0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  15.   0. ... 168. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524ddc0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  16.   0. ... 168. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524de80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  17.   0. ... 134. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524df40>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  18.   0. ... 132. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524dfd0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  19.   0. ... 130. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d730>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  20.   0. ... 128. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524da00>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  21.   0. ... 126. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524dbb0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  22.   0. ... 124. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524de50>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  23.   0. ... 122. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf9bb670>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 120. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4221fd0>\n",
      "\n",
      "~~~ Step 1 ~~~\n",
      "action_dict keys: 24 dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 24 dict_keys([2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 18, 22, 24, 1, 5, 6, 9, 15, 17, 19, 20, 21, 23])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 24 {2: 0, 3: 0, 4: 0, 7: 0, 8: 0, 1: -1, 5: -1, 6: -1, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 16: 0, 9: -1, 15: -1, 18: 0, 22: 0, 24: 0, 17: -1, 19: -1, 20: -1, 21: -1, 23: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 25 {2: False, 3: False, 4: False, 7: False, 8: False, 1: True, 5: True, 6: True, 10: False, 11: False, 12: False, 13: False, 14: False, 16: False, 9: True, 15: True, 18: False, 22: False, 24: False, 17: True, 19: True, 20: True, 21: True, 23: True, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 24 dict_keys([2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 18, 22, 24, 1, 5, 6, 9, 15, 17, 19, 20, 21, 23])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   2.   0. ...  40. 280.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4221b50>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  40. 282.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c8160>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   4.   0. ...  40. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c8190>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  40. 290.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c83d0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   8.   0. ...  40. 291.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c80a0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 327.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c8040>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 164. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c83a0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  12.   0. ... 166. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c82b0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  13.   0. ... 168. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c81c0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c8490>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  16.   0. ... 168. 321.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c8460>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  18.   0. ... 132. 201.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c8070>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  22.   0. ... 123. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c84c0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 120. 201.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c82e0>\n",
      "\n",
      "~~~ Step 2 ~~~\n",
      "action_dict keys: 14 dict_keys([2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 18, 22, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 14 dict_keys([3, 4, 7, 8, 10, 11, 13, 14, 18, 22, 24, 2, 12, 16])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 14 {3: 0, 4: 0, 7: 0, 8: 0, 2: -1, 10: 0, 11: 0, 13: 0, 14: 0, 12: -1, 16: -1, 18: 0, 22: 0, 24: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 15 {3: False, 4: False, 7: False, 8: False, 2: True, 10: False, 11: False, 13: False, 14: False, 12: True, 16: True, 18: False, 22: False, 24: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 14 dict_keys([3, 4, 7, 8, 10, 11, 13, 14, 18, 22, 24, 2, 12, 16])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  40. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4834f0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   4.   0. ...  40. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483100>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 290.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4833a0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   8.   0. ...  40. 292.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483220>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 162. 327.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483b80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 163. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483fd0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  13.   0. ... 167. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483250>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483f10>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  18.   0. ... 133. 201.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4832b0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  22.   0. ... 122. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be483f40>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 119. 201.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4c4220>\n",
      "\n",
      "~~~ Step 3 ~~~\n",
      "action_dict keys: 11 dict_keys([3, 4, 7, 8, 10, 11, 13, 14, 18, 22, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 11 dict_keys([3, 7, 10, 11, 13, 14, 18, 24, 4, 8, 22])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 11 {3: 0, 7: 0, 4: -1, 8: -1, 10: 0, 11: 0, 13: 0, 14: 0, 18: 0, 24: 0, 22: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 12 {3: False, 7: False, 4: True, 8: True, 10: False, 11: False, 13: False, 14: False, 18: False, 24: False, 22: True, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 11 dict_keys([3, 7, 10, 11, 13, 14, 18, 24, 4, 8, 22])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4701b80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 289.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471220>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 162. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471310>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 164. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471130>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  13.   0. ... 167. 327.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4714c0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4710d0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  18.   0. ... 133. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471490>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 118. 201.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4713a0>\n",
      "\n",
      "~~~ Step 4 ~~~\n",
      "action_dict keys: 8 dict_keys([3, 7, 10, 11, 13, 14, 18, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 8 dict_keys([3, 7, 10, 11, 13, 14, 18, 24])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 8 {3: 0, 7: 0, 10: 0, 11: 0, 13: 0, 14: 0, 18: 0, 24: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 9 {3: False, 7: False, 10: False, 11: False, 13: False, 14: False, 18: False, 24: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 8 dict_keys([3, 7, 10, 11, 13, 14, 18, 24])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4fe5f70>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 288.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421e50>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421ee0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 164. 327.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421c10>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  13.   0. ... 167. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421d30>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421af0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  18.   0. ... 132. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421d60>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 117. 201.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421df0>\n",
      "\n",
      "~~~ Step 5 ~~~\n",
      "action_dict keys: 8 dict_keys([3, 7, 10, 11, 13, 14, 18, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 8 dict_keys([3, 7, 10, 11, 13, 14, 24, 18])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 8 {3: 0, 7: 0, 10: 0, 11: 0, 13: 0, 14: 0, 24: 0, 18: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 9 {3: False, 7: False, 10: False, 11: False, 13: False, 14: False, 24: False, 18: True, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 8 dict_keys([3, 7, 10, 11, 13, 14, 24, 18])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471220>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  42. 288.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be4714c0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471130>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 163. 327.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471490>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  13.   0. ... 168. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0760>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0790>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 117. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e07f0>\n",
      "\n",
      "~~~ Step 6 ~~~\n",
      "action_dict keys: 7 dict_keys([3, 7, 10, 11, 13, 14, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 7 dict_keys([3, 7, 10, 11, 14, 24, 13])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 7 {3: 0, 7: 0, 10: 0, 11: 0, 14: 0, 13: -1, 24: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 8 {3: False, 7: False, 10: False, 11: False, 14: False, 13: True, 24: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 7 dict_keys([3, 7, 10, 11, 14, 24, 13])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf126790>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 288.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0a00>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 162. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f6100>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 163. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f6250>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f62b0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  24.   0. ... 118. 200.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f60a0>\n",
      "\n",
      "~~~ Step 7 ~~~\n",
      "action_dict keys: 6 dict_keys([3, 7, 10, 11, 14, 24])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 6 dict_keys([3, 7, 10, 11, 14, 24])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 6 {3: 0, 7: 0, 10: 0, 11: 0, 14: 0, 24: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 7 {3: False, 7: False, 10: False, 11: False, 14: False, 24: True, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 6 dict_keys([3, 7, 10, 11, 14, 24])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf2b8f10>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 289.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421fa0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be42e160>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 163. 327.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d640>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0a00>\n",
      "\n",
      "~~~ Step 8 ~~~\n",
      "action_dict keys: 5 dict_keys([3, 7, 10, 11, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 5 dict_keys([3, 7, 10, 11, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 5 {3: 0, 7: 0, 10: 0, 11: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 6 {3: False, 7: False, 10: False, 11: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 5 dict_keys([3, 7, 10, 11, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 283.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f6280>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 290.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471130>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4701ac0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  11.   0. ... 163. 328.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421ee0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 166. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be471220>\n",
      "\n",
      "~~~ Step 9 ~~~\n",
      "action_dict keys: 5 dict_keys([3, 7, 10, 11, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 5 dict_keys([3, 7, 10, 14, 11])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 5 {3: 0, 7: 0, 10: 0, 14: 0, 11: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 6 {3: False, 7: False, 10: False, 14: False, 11: True, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 5 dict_keys([3, 7, 10, 14, 11])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6dc0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 291.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a66d0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6b80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 166. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6bb0>\n",
      "\n",
      "~~~ Step 10 ~~~\n",
      "action_dict keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 4 {3: 0, 7: 0, 10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 5 {3: False, 7: False, 10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 4 dict_keys([3, 7, 10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be31dfa0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 290.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3bb0a0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be31df10>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 166. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf126a60>\n",
      "\n",
      "~~~ Step 11 ~~~\n",
      "action_dict keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 4 {3: 0, 7: 0, 10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 5 {3: False, 7: False, 10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 4 dict_keys([3, 7, 10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  41. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4fea460>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  40. 290.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3355e0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 162. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be335730>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 166. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be335880>\n",
      "\n",
      "~~~ Step 12 ~~~\n",
      "action_dict keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 4 {3: 0, 7: 0, 10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 5 {3: False, 7: False, 10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 4 dict_keys([3, 7, 10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   3.   0. ...  40. 284.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be335760>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 290.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be335b50>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf126790>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 165. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be335b80>\n",
      "\n",
      "~~~ Step 13 ~~~\n",
      "action_dict keys: 4 dict_keys([3, 7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 4 dict_keys([7, 10, 14, 3])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 4 {7: 0, 3: -1, 10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 5 {7: False, 3: True, 10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 4 dict_keys([7, 10, 14, 3])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  41. 289.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f6100>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 326.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c50760a0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 165. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421f10>\n",
      "\n",
      "~~~ Step 14 ~~~\n",
      "action_dict keys: 3 dict_keys([7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 3 dict_keys([7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 3 {7: 0, 10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 4 {7: False, 10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 3 dict_keys([7, 10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.   7.   0. ...  40. 289.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4701dc0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 161. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c4701ac0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 165. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0b20>\n",
      "\n",
      "~~~ Step 15 ~~~\n",
      "action_dict keys: 3 dict_keys([7, 10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 3 dict_keys([10, 14, 7])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 3 {7: -1, 10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 4 {7: True, 10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 3 dict_keys([10, 14, 7])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 162. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0ac0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 165. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be42e0d0>\n",
      "\n",
      "~~~ Step 16 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 162. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421f10>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 165. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0790>\n",
      "\n",
      "~~~ Step 17 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 163. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3e0af0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 165. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be335d30>\n",
      "\n",
      "~~~ Step 18 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 163. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be31df10>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 166. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3f6220>\n",
      "\n",
      "~~~ Step 19 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 164. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be2f1130>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 166. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be2f10a0>\n",
      "\n",
      "~~~ Step 20 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 163. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be2f1190>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be2c2f10>\n",
      "\n",
      "~~~ Step 21 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 164. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf1f72b0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d7f0>\n",
      "\n",
      "~~~ Step 22 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 164. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf1b0b80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 325.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d640>\n",
      "\n",
      "~~~ Step 23 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 164. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.North'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3bb070>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 167. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59d0a433d0>\n",
      "\n",
      "~~~ Step 24 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 164. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c56e40d0>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf16b130>\n",
      "\n",
      "~~~ Step 25 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 165. 324.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf1b0b80>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59bf2b8f10>\n",
      "\n",
      "~~~ Step 26 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 165. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6b50>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.East'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6820>\n",
      "\n",
      "~~~ Step 27 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 166. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6520>\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  14.   0. ... 168. 323.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be3a6d60>\n",
      "\n",
      "~~~ Step 28 ~~~\n",
      "action_dict keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 2 dict_keys([10, 14])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 2 {10: 0, 14: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 3 {10: False, 14: True, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 2 dict_keys([10, 14])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 166. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be2f10a0>\n",
      "\n",
      "~~~ Step 29 ~~~\n",
      "action_dict keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 1 {10: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 2 {10: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 1 dict_keys([10])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 167. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59c524d640>\n",
      "\n",
      "~~~ Step 30 ~~~\n",
      "action_dict keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 1 {10: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 2 {10: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 1 dict_keys([10])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 168. 322.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.West'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be2adac0>\n",
      "\n",
      "~~~ Step 31 ~~~\n",
      "action_dict keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 1 {10: 0}\n",
      "RLlibMultiAgentTeamBasedEnv done: 2 {10: False, '__all__': False}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 1 dict_keys([10])\n",
      "rllib_actions obs of agent: (1, 10939) [[  1.  10.   0. ... 168. 321.  15.]]\n",
      "rllib_actions returned by agent: [defaultdict(<class 'dict'>, {<class 'nmmo.io.action.Attack'>: {<class 'nmmo.io.action.Style'>: None, <class 'nmmo.io.action.Target'>: None}, <class 'nmmo.io.action.Buy'>: {<class 'nmmo.io.action.Item'>: None}, <class 'nmmo.io.action.Comm'>: {<class 'nmmo.io.action.Token'>: None}, <class 'nmmo.io.action.Move'>: {<class 'nmmo.io.action.Direction'>: <class 'nmmo.io.action.South'>}, <class 'nmmo.io.action.Sell'>: {<class 'nmmo.io.action.Item'>: None, <class 'nmmo.io.action.Price'>: None}, <class 'nmmo.io.action.Use'>: {<class 'nmmo.io.action.Item'>: None}})]\n",
      "ob of agent: <nmmo.scripting.Observation object at 0x7f59be421af0>\n",
      "\n",
      "~~~ Step 32 ~~~\n",
      "action_dict keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv obs keys: 1 dict_keys([10])\n",
      "RLlibMultiAgentTeamBasedEnv rew: 1 {10: -1}\n",
      "RLlibMultiAgentTeamBasedEnv done: 2 {10: True, '__all__': True}\n",
      "RLlibMultiAgentTeamBasedEnv info keys: 1 dict_keys([10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/collectors/agent_collector.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(v)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# perform one training epoch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompleted RLlib epoch!!!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/tune/trainable/trainable.py:347\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warmup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n\u001b[1;32m    346\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 347\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep() needs to return a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:661\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m     (\n\u001b[1;32m    654\u001b[0m         results,\n\u001b[1;32m    655\u001b[0m         train_iter_ctx,\n\u001b[1;32m    656\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 661\u001b[0m     results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:2378\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[38;5;66;03m# In case of any failures, try to ignore/recover the failed workers.\u001b[39;00m\n\u001b[1;32m   2377\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2378\u001b[0m             num_recreated \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_recover_from_step_attempt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m                \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m                \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[43m                \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore_worker_failures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrecreate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecreate_failed_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2384\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_recreated_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_recreated\n\u001b[1;32m   2386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, train_iter_ctx\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:2190\u001b[0m, in \u001b[0;36mAlgorithm.try_recover_from_step_attempt\u001b[0;34m(self, error, worker_set, ignore, recreate)\u001b[0m\n\u001b[1;32m   2186\u001b[0m \u001b[38;5;66;03m# Any other exception.\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;66;03m# Allow logs messages to propagate.\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m-> 2190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m   2192\u001b[0m removed_workers, new_workers \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;66;03m# Search for failed workers and try to recover (restart) them.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:2373\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[1;32m   2372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_execution_plan_api\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m-> 2373\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2375\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/ppo.py:407\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    404\u001b[0m         worker_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers, max_agent_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    405\u001b[0m     )\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     train_batch \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_batch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mas_multi_agent()\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39magent_steps()\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/execution/rollout_ops.py:97\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (max_agent_or_env_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m agent_or_env_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     91\u001b[0m     max_agent_or_env_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m agent_or_env_steps \u001b[38;5;241m<\u001b[39m max_agent_or_env_steps\n\u001b[1;32m     93\u001b[0m ):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# No remote workers in the set -> Use local worker for collecting\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# samples.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mremote_workers():\n\u001b[0;32m---> 97\u001b[0m         sample_batches \u001b[38;5;241m=\u001b[39m [\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         sample_batches \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    101\u001b[0m             [worker\u001b[38;5;241m.\u001b[39msample\u001b[38;5;241m.\u001b[39mremote() \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mremote_workers()]\n\u001b[1;32m    102\u001b[0m         )\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py:806\u001b[0m, in \u001b[0;36mRolloutWorker.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_start\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    800\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating sample batch of size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_fragment_length\n\u001b[1;32m    803\u001b[0m         )\n\u001b[1;32m    804\u001b[0m     )\n\u001b[0;32m--> 806\u001b[0m batches \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    807\u001b[0m steps_so_far \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    808\u001b[0m     batches[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcount\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_steps_by \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m batches[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39magent_steps()\n\u001b[1;32m    811\u001b[0m )\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# In truncate_episodes mode, never pull more than 1 batch per env.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;66;03m# This avoids over-running the target batch size.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py:92\u001b[0m, in \u001b[0;36mSamplerInput.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@override\u001b[39m(InputReader)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleBatchType:\n\u001b[0;32m---> 92\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     93\u001b[0m     batches\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extra_batches())\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batches) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py:282\u001b[0m, in \u001b[0;36mSyncSampler.get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;129m@override\u001b[39m(SamplerInput)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleBatchType:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env_runner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, RolloutMetrics):\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics_queue\u001b[38;5;241m.\u001b[39mput(item)\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py:684\u001b[0m, in \u001b[0;36m_env_runner\u001b[0;34m(worker, base_env, extra_batch_callback, horizon, normalize_actions, clip_actions, multiple_episodes_in_batch, callbacks, perf_stats, soft_horizon, no_done_at_end, observation_fn, sample_collector, render)\u001b[0m\n\u001b[1;32m    681\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# types: Set[EnvID], Dict[PolicyID, List[_PolicyEvalData]],\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m#       List[Union[RolloutMetrics, SampleBatchType]]\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m active_envs, to_eval, outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_process_observations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactive_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43munfiltered_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munfiltered_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrewards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdones\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultiple_episodes_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiple_episodes_in_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoft_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoft_horizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_done_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_done_at_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_collector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_collector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m perf_stats\u001b[38;5;241m.\u001b[39mincr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_obs_processing_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t1)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py:1041\u001b[0m, in \u001b[0;36m_process_observations\u001b[0;34m(worker, base_env, active_episodes, unfiltered_obs, rewards, dones, infos, horizon, multiple_episodes_in_batch, callbacks, soft_horizon, no_done_at_end, observation_fn, sample_collector)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# If, we are not allowed to pack the next episode into the same\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# SampleBatch (batch_mode=complete_episodes) -> Build the\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# MultiAgentBatch from a single episode and add it to \"outputs\".\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# (to e.g. properly flush and clean up the SampleCollector's buffers),\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# but then discard the entire batch and don't return it.\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m episode\u001b[38;5;241m.\u001b[39mis_faulty \u001b[38;5;129;01mor\u001b[39;00m episode\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1041\u001b[0m     ma_sample_batch \u001b[38;5;241m=\u001b[39m \u001b[43msample_collector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess_episode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhit_horizon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msoft_horizon\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_dones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_dones\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_faulty\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmultiple_episodes_in_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m episode\u001b[38;5;241m.\u001b[39mis_faulty:\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ma_sample_batch:\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:435\u001b[0m, in \u001b[0;36mSimpleListCollector.postprocess_episode\u001b[0;34m(self, episode, is_done, check_dones, build)\u001b[0m\n\u001b[1;32m    433\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_key_to_policy_id[(eps_id, agent_id)]\n\u001b[1;32m    434\u001b[0m     policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map[pid]\n\u001b[0;32m--> 435\u001b[0m     pre_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_requirements\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     pre_batches[agent_id] \u001b[38;5;241m=\u001b[39m (policy, pre_batch)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Apply reward clipping before calling postprocessing functions.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/ray/rllib/evaluation/collectors/agent_collector.py:395\u001b[0m, in \u001b[0;36mAgentCollector.build_for_training\u001b[0;34m(self, view_requirements)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# in some multi-agent cases shifted_data may be an empty list.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# In this case we should just create an empty array and return it.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shifted_data:\n\u001b[0;32m--> 395\u001b[0m     shifted_data_np \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshifted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     shifted_data_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(shifted_data)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/scratch/zciccwf/py36/envs/nmmo/lib/python3.9/site-packages/numpy/core/shape_base.py:426\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    424\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    428\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    429\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# perform one training epoch\n",
    "results = trainer.train()\n",
    "print(f'Completed RLlib epoch!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086054b9-22e2-4702-9bf0-a25eb5726036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b4ad7-222f-4ce2-8a6f-95e068ce7b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf358d-a73a-44c2-9d59-dd6fa743e857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd684627-8389-4aac-a0c6-82b7a137a392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f45115-62f2-4030-a934-2becaa3ad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RLlibScriptedHybridAgentTeam(Team):\n",
    "    def __init__(self,\n",
    "                 team_id,\n",
    "                 env_config,\n",
    "                 paths_to_scripted_agents_cls,\n",
    "                 **kwargs):\n",
    "        super().__init__(team_id, env_config)\n",
    "        self.id = team_id\n",
    "        print(f'team_id: {self.id}')\n",
    "        \n",
    "        self.scripted_agents = [get_class_from_path(path_to_scripted_agent_cls)(config=env_config, idx=int(idx)) for idx, path_to_scripted_agent_cls in paths_to_scripted_agents_cls.items()]\n",
    "        self.scripted_agent_ids = set([int(idx) for idx in paths_to_scripted_agents_cls.keys()])\n",
    "        self.scripted_agent_idxs = set([idx for idx in range(len(self.scripted_agents))])\n",
    "        \n",
    "        self.rllib_agents = [None]\n",
    "        self.rllib_agent_ids = set([sorted(self.scripted_agent_ids)[-1]+1])\n",
    "        self.rllib_agent_idxs = set([len(self.scripted_agents)+idx for idx in range(1, len(self.rllib_agents)+1)])\n",
    "        \n",
    "        print(f'scripted_agents: {self.scripted_agents}')\n",
    "        print(f'scripted_agent_ids: {self.scripted_agent_ids}')\n",
    "        print(f'scripted_agent_idxs: {self.scripted_agent_idxs}')\n",
    "        \n",
    "        print(f'rllib_agents: {self.rllib_agents}')\n",
    "        print(f'rllib_agent_ids: {self.rllib_agent_ids}')\n",
    "        print(f'rllib_agent_idxs: {self.rllib_agent_idxs}')\n",
    "        \n",
    "        # init multi-agent env for team to interact with\n",
    "        agent_ids_to_agents = {}\n",
    "        for agent_id, agent in zip(self.scripted_agent_ids, self.scripted_agents):\n",
    "            agent_ids_to_agents[agent_id] = agent\n",
    "        for agent_id, agent in zip(self.rllib_agent_ids, self.rllib_agents):\n",
    "            agent_ids_to_agents[agent_id] = agent\n",
    "        self.team_env = RLlibMultiAgentTeamEnv(\n",
    "                                            env_config=env_config,\n",
    "                                            agent_ids_to_agents=agent_ids_to_agents,\n",
    "                                            team_id=self.id,\n",
    "                                        )\n",
    "        print(f'team_env: {self.team_env}')\n",
    "        \n",
    "    def reset(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def get_rllib_agent_actions(self, observations):\n",
    "        return {i: self.agents[i](obs) for i, obs in observations.items() if i in self.rllib_agent_idxs}\n",
    "    \n",
    "    def get_scripted_agent_actions(self, observations):\n",
    "        return {i: self.agents[i](obs) for i, obs in observations.items() if i in self.scripted_agent_idxs}\n",
    "    \n",
    "    def post_process_actions(self, actions):\n",
    "        for i in actions:\n",
    "            for atn, args in actions[i].items():\n",
    "                for arg, val in args.items():\n",
    "                    if arg.argType == nmmo.action.Fixed:\n",
    "                        actions[i][atn][arg] = arg.edges.index(val)\n",
    "                    elif arg == nmmo.action.Target:\n",
    "                        actions[i][atn][arg] = self.get_target_index(\n",
    "                            val, self.agents[i].ob.agents)\n",
    "                    elif atn in (nmmo.action.Sell,\n",
    "                                 nmmo.action.Use) and arg == nmmo.action.Item:\n",
    "                        actions[i][atn][arg] = self.get_item_index(\n",
    "                            val, self.agents[i].ob.items)\n",
    "                    elif atn == nmmo.action.Buy and arg == nmmo.action.Item:\n",
    "                        actions[i][atn][arg] = self.get_item_index(\n",
    "                            val, self.agents[i].ob.market)\n",
    "        return actions\n",
    "    \n",
    "    def act(self, observations, rewards=None):\n",
    "        '''\n",
    "        During training, pass rewards from last step to update RLlib policy.\n",
    "        \n",
    "        During inference (e.g. when make submission), no rewards need to be\n",
    "        passed to act().\n",
    "        '''\n",
    "        if \"stat\" in observations:\n",
    "            stat = observations.pop(\"stat\")\n",
    "            \n",
    "        if rewards is None:\n",
    "            # agent is training, register rewards\n",
    "            # if an action was chosen at the last step, assign team reward for taking that action\n",
    "            # TODO\n",
    "            pass\n",
    "        else:\n",
    "            # not training, no need to consider rewards\n",
    "            pass\n",
    "        \n",
    "        # TODO\n",
    "        # get team actions for this step\n",
    "        actions = {}\n",
    "        actions.update(self.get_scripted_agent_actions(observations))\n",
    "        actions.update(self.get_rllib_agent_actions(observations))\n",
    "        \n",
    "        # return team actions to TeamBasedEnv\n",
    "        return self.post_process_actions(actions)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_item_index(instance: int, items: np.ndarray) -> int:\n",
    "        for i, itm in enumerate(items):\n",
    "            id_ = nmmo.scripting.Observation.attribute(itm,\n",
    "                                                       nmmo.Serialized.Item.ID)\n",
    "            if id_ == instance:\n",
    "                return i\n",
    "        raise ValueError(f\"Instance {instance} not found\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_target_index(target: int, agents: np.ndarray) -> int:\n",
    "        targets = [\n",
    "            x for x in [\n",
    "                nmmo.scripting.Observation.attribute(\n",
    "                    agent, nmmo.Serialized.Entity.ID) for agent in agents\n",
    "            ] if x\n",
    "        ]\n",
    "        return targets.index(target)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# env config\n",
    "path_to_env_cls = 'neurips2022nmmo.TeamBasedEnv'\n",
    "path_to_env_config_cls = 'deep_nmmo.envs.team_based_env.env_configs.custom_competition_config.CustomCompetitionConfig'\n",
    "env_config_kwargs = None\n",
    "# teams_config = {\n",
    "#     'Combat':\n",
    "#         {\n",
    "#             'path_to_team_cls': 'neurips2022nmmo.scripted.CombatTeam'\n",
    "#         },\n",
    "#     'Mixture':\n",
    "#         {\n",
    "#             'path_to_team_cls': 'neurips2022nmmo.scripted.MixtureTeam'\n",
    "#         },\n",
    "# }\n",
    "rllib_paths_to_scripted_agents_cls = {\n",
    "                                    '0': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    '1': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    '2': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    '3': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    '4': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    '5': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    '6': 'neurips2022nmmo.scripted.baselines.Mage',\n",
    "                                    }\n",
    "\n",
    "teams_config = {\n",
    "    'RLlib': {'cls': RLlibScriptedHybridAgentTeam, 'kwargs': {'paths_to_scripted_agents_cls': rllib_paths_to_scripted_agents_cls}},\n",
    "    'Combat': {'cls': neurips2022nmmo.scripted.CombatTeam, 'kwargs': {}},\n",
    "    'Mixture': {'cls': neurips2022nmmo.scripted.MixtureTeam, 'kwargs': {}},\n",
    "}\n",
    "teams_copies = [1, 2]        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# init env params\n",
    "env_config = get_class_from_path(path_to_env_config_cls)()\n",
    "\n",
    "teams = []\n",
    "for team_id, params in teams_config.items():\n",
    "    team_cls, team_kwargs = params['cls'], params['kwargs']\n",
    "    team_kwargs['env_config'] = env_config\n",
    "    team_kwargs['team_id'] = team_id\n",
    "    teams.append(team_cls(**team_kwargs))\n",
    "print(f'Teams: {teams}')\n",
    "\n",
    "for i, team in enumerate(teams):\n",
    "    class Agent(nmmo.Agent):\n",
    "        name = f'{team.id}'\n",
    "        policy = f'{team.id}'\n",
    "    env_config.PLAYERS[i] = Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9830f-0a09-4ad1-8a94-2b9c2e78c47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0712292-f064-4b5c-b4f8-be35be7e6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {1: 3, 2: 2, 4: 5}\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cda414-e36d-4e86-99cf-f6ff61d535c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ad6ba-6af9-4b32-8199-e69879de67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up configs\n",
    "\n",
    "# env config\n",
    "path_to_env_cls = 'neurips2022nmmo.TeamBasedEnv'\n",
    "path_to_env_config_cls = 'deep_nmmo.envs.team_based_env.env_configs.custom_competition_config.CustomCompetitionConfig'\n",
    "env_config_kwargs = None\n",
    "teams_config = {\n",
    "    'Combat':\n",
    "        {\n",
    "            'path_to_team_cls': 'neurips2022nmmo.scripted.CombatTeam'\n",
    "        },\n",
    "    'Mixture':\n",
    "        {\n",
    "            'path_to_team_cls': 'neurips2022nmmo.scripted.MixtureTeam'\n",
    "        },\n",
    "}\n",
    "teams_copies = [1, 2]\n",
    "\n",
    "# init env params\n",
    "env_config, teams_copies, teams = init_env_params(path_to_env_config_cls=path_to_env_config_cls,\n",
    "                                                  env_config_kwargs=env_config_kwargs,\n",
    "                                                  teams_copies=teams_copies,\n",
    "                                                  teams_config=teams_config)\n",
    "\n",
    "\n",
    "\n",
    "# rllib config\n",
    "path_to_rllib_trainer_cls = 'ray.rllib.agents.ppo.PPOTrainer'\n",
    "\n",
    "# ma_cls = make_multi_agent(lambda env_config: get_class_from_path(path_to_env_cls)(env_config))\n",
    "# print(ma_cls)\n",
    "# dummy_env = ma_cls(env_config)\n",
    "# print(dummy_env)\n",
    "# print(type(dummy_env))\n",
    "# _ = dummy_env.reset()\n",
    "\n",
    "\n",
    "dummy_env = RLlibMultiAgentTeamBasedEnv(\n",
    "                                    path_to_env_cls=path_to_env_cls,\n",
    "                                    path_to_env_config_cls=path_to_env_config_cls,\n",
    "                                    teams_copies=teams_copies,\n",
    "                                    teams_config=teams_config,\n",
    "                                )\n",
    "print(dummy_env)\n",
    "\n",
    "policies = {}\n",
    "for policy_id in dummy_env._agent_ids:\n",
    "    policies[str(policy_id)] = PolicySpec(\n",
    "                                # policy_class=player.__class__, # infer automatically from algorithm\n",
    "                                # observation_space=dummy_env.observation_space(player_id),\n",
    "                                # action_space=dummy_env.action_space(player_id),\n",
    "                                config={},\n",
    "                            )\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    '''Maps agent ID to corresponding policy ID of policy which agent should use.'''\n",
    "    return str(agent_id)\n",
    "\n",
    "multiagent_config = {\n",
    "    'policies': policies,\n",
    "    'policy_mapping_fn': policy_mapping_fn,\n",
    "}\n",
    "\n",
    "\n",
    "rllib_config = {\n",
    "    'framework': 'torch',\n",
    "    \n",
    "    'multiagent': multiagent_config,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce6872-6e7e-49a4-b798-bc1cac5ad442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54491403-ac9e-4141-8786-6470bfc14791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register env with ray\n",
    "register_env(path_to_env_cls.split('.')[-1], lambda env_config: make_multi_agent(get_class_from_path(path_to_env_cls))(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf17572-0d23-49a2-9788-d706f95b412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update rllib config with observation and action spaces\n",
    "# dummy_env = get_class_from_path(path_to_env_cls)(env_config)\n",
    "# agent = 0\n",
    "# rllib_config['observation_space'] = dummy_env.observation_space(agent)\n",
    "# rllib_config['action_space'] = dummy_env.action_space(agent)\n",
    "\n",
    "# init rllib trainer\n",
    "trainer = get_class_from_path(path_to_rllib_trainer_cls)(config=rllib_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c3fa2-1835-4522-87a0-99a5e6f9b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TeamBasedEnv(env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c153f72-dbf4-4fca-94db-2eb72509f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space(0))\n",
    "print(type(env.observation_space(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e838899-8439-44e7-8ca0-b64677d25f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in env.observation_space(0).items():\n",
    "    print(f'\\nkey: {key}')\n",
    "    print(f'val: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9adc6-d631-40d7-ba53-bc6a8bc0dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "edges = [0, 1, 2, 3]\n",
    "for edge in edges:\n",
    "    if edge == 1:\n",
    "        max_edge = edge\n",
    "print(f'edge: {edge} | max_edge: {max_edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f7cb9-04ab-4c3c-85c3-ccf1f8624d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(-1)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3ad2e-c523-48bb-a5e8-963bf81bff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0 < len([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea498f0-e452-4935-9fcf-87b21e2b3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "class Job:\n",
    "    def __init__(self,\n",
    "                 job_id,\n",
    "                 original_job=None):\n",
    "        self.job_id = job_id\n",
    "        if original_job is None:\n",
    "            self.original_job = copy.deepcopy(self)\n",
    "        else:\n",
    "            self.original_job = original_job\n",
    "        \n",
    "job_id = 0\n",
    "original_job = Job(job_id=job_id, original_job=None)\n",
    "print(f'original_job job_id: {original_job.job_id} | original_job job_id: {original_job.original_job.job_id}')\n",
    "\n",
    "print('')\n",
    "job_id = 1\n",
    "start_t = time.time()\n",
    "# _original_job = copy.deepcopy(original_job)\n",
    "_original_job = copy.copy(original_job)\n",
    "# _original_job = original_job\n",
    "_original_job.job_id = job_id\n",
    "print(f'Updated _original_job in {time.time() - start_t} s')\n",
    "job_1 = Job(job_id=1, original_job=_original_job)\n",
    "print(f'original_job job_id: {original_job.job_id} | original_job job_id: {original_job.original_job.job_id}')\n",
    "print(f'job_1 job_id: {job_1.job_id} | original_job job_id: {job_1.original_job.job_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552c0d1-3532-4706-bb53-cfae7dedb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096eb99-9f68-47d8-91a5-0aa9431bdebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmmo",
   "language": "python",
   "name": "nmmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
